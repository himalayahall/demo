{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marimo as mo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {},
   "source": [
    "# Market Data Simulator\n",
    "\n",
    "## Tech Stack\n",
    "\n",
    "- Java, Spring Boot, Spring WebFlux, Google Guava (cache), Gradle, JUnit, Mockito, VS Code\n",
    "\n",
    "## Assumptions\n",
    "\n",
    "1. I will assume that the simulator will be used by a small number of clients (e.g. >= 0, <= 20). Replay sessions for a small number of clients can be handled on a single server using native Java threads (or threadpool). For a greater number of clients on a single server, virtual threads would work well but they are not quite production grade in Java 17. In any case, one could always spin up additional replay servers along with a load balancer to fan out sessions among servers\n",
    "  - [sree] ok\n",
    "\n",
    "2. I will assume that CSV file contents can fit into replay process memory (all data is cached)\n",
    "  - [sree] ok\n",
    "\n",
    "3. I will assume that simple streaming of data - e.g. server side events or other streaming strategy - is adequate (instead of using pub/sub to offload streaming responsibility to a message broker)\n",
    "  -[ sree] correct\n",
    "\n",
    "4. I will assume that a replay session that is interrupted midstream will not require automatic session reconnect/restart capability\n",
    "  - [sree] correct\n",
    "\n",
    "5. There will be two 'clocks' - a Replay clock and a Simulation clock. The Replay clock (per session) will control the frequency (how often) of data publication to a replay session. The Simulation clock (also per session) will control the quantity (how much) data is published to a replay session\n",
    "  - [sree] ok. Had to read the next 2 to understand this. So your ‘Replay clock’ specifies the publishing cadence. Yes, that works.\n",
    "\n",
    "6. Replay clock granularity will be 1 second (might be configurable) - i.e. data events will be published to each session at 1 second intervals\n",
    "  - [sree]  1 sec would likely need some buffering and smoothening out by the UI. Try for an approach that does not require UI to buffer/smooth out. Assume a reasonably powerful server for your app, and the limited number of clients that you noted above to keep the design simple.\n",
    "\n",
    "7. Simulation clock granularity will be governed by the replay rate (default: 1.0, may be changed by client). For example, a replay rate of 1.0 would advance the simulation\n",
    "clock in lockstep with the replay clock. And a replay rate of 1.5 would advance the simulation clock at 1.5X the Replay rate - e.g. each time the replay clock advances by 1 second (1000 milliseconds), the simulation clock will advance by 1.5 seconds (1500 millisecs)\n",
    "  - [sree] yes. Support both speed up and slow down.\n",
    "\n",
    "8. During each publishing interval (see 6) all unpublished events within the session simulation clock window will be published\n",
    "  - [sree] ok\n",
    "\n",
    "9. Data will be published as JSON (CSV row data -> Record -> JSON conversion done on replay server)\n",
    "  - [sree] ok\n",
    "\n",
    "10. Security (Https) and authentication out of scope"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vblA",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "### Functional\n",
    "\n",
    "1. Stream market data events to Web clients.\n",
    "2. Allow multiple clients - i.e. mujst support concurrent replay sessions.\n",
    "3. Clients should be able to control replay sessions by sending the following commands:\n",
    "    - **Create** replay session.\n",
    "    - **Start** & **Stop** session.\n",
    "    - **Rewind** session - i.e. rewind to beginning of market data event stream.\n",
    "    - **Set replay speed** - i.e. **speed up** replay to N, where $N \\gt 1.0$. **Slow down** replay to M where $0.0 \\lt M \\lt 1.0$.\n",
    "    - **Fast forward** replay session - i.e. skip **N** market data events in replay session, where $N \\gt 0$. Forwarding past event stream stops the replay session.\n",
    "    - **Goto event** - i.e. jump to specific market data event (by event ID) in replay session.\n",
    "\n",
    "### Non-Functional\n",
    "\n",
    "1. **Performance**\n",
    "    - **Throughput** -  replay at sustained high throughput (up to 3000 events/sec).\n",
    "    - **Scale** - support large number of clients [0, 100] without performance degradation.\n",
    "   - **Stability**\n",
    "2. **Design Quality** - design should be easy to understand and to update.\n",
    "3. **Code Quality** - code should be production quality with good documentation.\n",
    "4. **Testing** - implementation should be easily testable, congtain test scaffolding, and performance claims should be backed by evidence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bkHC",
   "metadata": {},
   "source": [
    "## Design decisions\n",
    "\n",
    "- **Spring Boot application** with **RESTful APIs** for replay controls.\n",
    "- **Reactive SpringFlux** application for streaming market data events.\n",
    "- **Data** -> read from [CSV file](https://github.com/himalayahall/demo/blob/9f346eac082b2ba9300041759bce3413532ba7fa/src/main/resources/marketdata-for-coding-challenge.csv). FYI - file had invisible BOM (invisible byte-order mark) which caused a lot of head scratching before I pinpointed the cause and fixed it (see below).\n",
    "- **Session cache** - sessions are stored in Google Guava cache, **stale** sessions are ejected after a configurable timeout in `application.properties`. Default cache cofiguration is `1 HOUR`.\n",
    "- **Sliding window** -> virtual sliding window moves over cached events, during each publishing cycle ALL events under sliding window are published. Sliding window and event publication controls are set through `application.properties`:\n",
    "\n",
    "    - **publishTimerMillis** -  controls how often the sliding window is moved, default: `1 millisecond`.\n",
    "    - **replayClockMillis** - tracks progress of time in replay session; controls the sliding window size. When a session is `created` or `rewound`, the `replayClockMillis` is initialized to timestamp of the first data event. At each publishing cycle all `unpublished` events with $timestamp \\leq replayClockMillis$ are published and then `replayClockMillis` is set to $replayClockMillis + (replaySpeed \\times publishTimerMillis$).\n",
    "\n",
    "  - **replaySpeed** - controls how fast the replay clock advances. For example, suppose  $publishTimerMillis =  1$ and $replaySpeed = 1.0$. During each publishing cycle `replayClockMillis` will advance by $replaySpeed \\times publishTimerMillis$.\n",
    "\n",
    "    Suppose `replaySpeed` is bumped up to `2.0`. During each subsequent publishing cycle, `replayClockMillis` will advance  $2.0 \\times publishTimerMillis$ milliseconds. For example, with default replay settings,  `replayClockMillis` will advance `2 milliseconds` for each `1 millisecond` advance of the system clock. This works both for speeding up ($replaySpeed \\gt 1.0$) and slowing down ($replaySpeed \\lt 1.0)$ replay.\n",
    "\n",
    "  - Automated performance testing - taking a page out the guidebook on best practices in data science, use a Notebook infrastructure for documenting the implementation and for automated performance testing. This brings together the documentation (installation, API usage, etc.), manual testing guidelines via RESTful API, and automated testing via Python in a unified document. This document you are reading was exported from the [Marimo](https://marimo.io) Notebook. Marimo is a [Jupyter](https://jupyter.org) alternative, purpose built as a git-friendly dev environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lEQa",
   "metadata": {},
   "source": [
    "## Key classes\n",
    "- **MarketDataController** - entry point for the REST API.\n",
    "- **ReplayService** - services for managing session lifecycles.\n",
    "- **ReplaySession** - interface with methods for session commands (stop, start, etc.)\n",
    "    - **ReplaySessionImpl** - default implementation of ReplaySession.\n",
    "- **MarketDataEvent** - market data record (data model).\n",
    "- **CSVReaderService** - CSV reader service interface\n",
    "\n",
    "      - **JacksonCSVReader** - Jackson implementation (default).\n",
    "\n",
    "      - **ApacheCSVReaderService** - Apache Commons implementation. Tried this first but the API was *messy* (deprecated API, dealing with byte-order mark, BOM, was cumbersome)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PKri",
   "metadata": {},
   "source": [
    "## Unit Testing\n",
    "\n",
    "- Replay service functionality is tested via `unit tests`. Key functionality is tested including `create`, `start`, `stop`, `set speed`, `rewind`, `forward`, and `jump to event`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Xref",
   "metadata": {},
   "source": [
    "## Replay service installation\n",
    "  - Prerequisites - Java (17 or higher), Java IDE (VSCode, IntelliJ, Eclipse).\n",
    "  - Clone [repository](https://github.com/himalayahall/demo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SFPL",
   "metadata": {},
   "source": [
    "### Running\n",
    "\n",
    "- Load project in VSCode (or another IDE).\n",
    "- Open terminal inside VSCode for viewing replay service logs.\n",
    "- Run application inside VSCode.\n",
    "- Confirm successful launch through logs in terminal.\n",
    "-----\n",
    "```\n",
    "     ____          _            __ _ _\n",
    " /\\\\ / ___'_ __ _ _(_)_ __  __ _ \\ \\ \\ \\\n",
    "( ( )\\___ | '_ | '_| | '_ \\/ _` | \\ \\ \\ \\\n",
    " \\\\/  ___)| |_)| | | | | || (_| |  ) ) ) )\n",
    "  '  |____| .__|_| |_|_| |_\\__, | / / / /\n",
    " =========|_|==============|___/=/_/_/_/\n",
    " :: Spring Boot ::                (v3.1.5)\n",
    "\n",
    "2025-02-02T10:12:06.627-05:00  INFO 2351 --- [           main] com.pragma.demo.DemoApplication          : Starting DemoApplication using Java 17.0.10 with PID 2351 (/Users/jawaidhakim/Jobs/MarketAxess/demo/bin/main started by jawaidhakim in /Users/jawaidhakim/Jobs/MarketAxess/demo)\n",
    "2025-02-02T10:12:06.630-05:00  INFO 2351 --- [           main] com.pragma.demo.DemoApplication          : No active profile set, falling back to 1 default profile: \"default\"\n",
    "2025-02-02T10:12:07.551-05:00  INFO 2351 --- [           main] com.pragma.demo.service.ReplayService    : Events: 3452, First: 09:30:00:213, Last: 09:31:58:406\n",
    "2025-02-02T10:12:08.076-05:00  INFO 2351 --- [           main] o.s.b.web.embedded.netty.NettyWebServer  : Netty started on port 8080\n",
    "2025-02-02T10:12:08.093-05:00  INFO 2351 --- [           main] com.pragma.demo.DemoApplication          : Started DemoApplication in 1.753 seconds (process running for 2.081)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "BYtC",
   "metadata": {},
   "source": [
    "## RESTful API\n",
    "\n",
    "### Documentation\n",
    "- Static (may be stale) OpenAPI Documentation can be found [here](https://github.com/himalayahall/demo/blob/5bbd1c5971250a09ce0872e3b4562cf2fa36e17a/api-documentation.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RGSE",
   "metadata": {},
   "source": [
    "### Using the API\n",
    "\n",
    "RESTful API can be used in the usual ways. Below are 2 no-code ways of using tthe API:\n",
    "\n",
    "  1. **Spring OpenAPI**  interface is baked into the application. To use this interface - [run the application](#running) and then go to http://localhost:8080/swagger-ui.html.\n",
    "\n",
    "  2. Use [curl](https://curl.se) to access the API. For example, execute `curl -X GET http://localhost:8080/session/subscribe/e8cc93be-3723-4c37-8681-b3fa6d3b7a79` from a terminal to subscribe for events on session\n",
    "`e8cc93be-3723-4c37-8681-b3fa6d3b7a79`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Kclp",
   "metadata": {},
   "source": [
    "## Testing and QA\n",
    "\n",
    "Replay service can be tested manually or via automation.\n",
    "\n",
    "### Manual recipe for kicking the tires\n",
    "\n",
    "1. Enable logging\n",
    "\n",
    "     > - In *application.properties*, locate `logging.level.com.pragma.demo=INFO` and replace it with `logging.level.com.pragma.demo=TRACE`. This will enable TRACE level logging which will be come in handy for manual testing.\n",
    "\n",
    "2. [Start replay service](#installation).\n",
    "3. Go to http://localhost:8080/swagger-ui.html.\n",
    "\n",
    " <a id=\"create-session\"></a>\n",
    "4. Create replay session\n",
    "\n",
    "> - Click `POST /mktdata/session`.\n",
    "> - Click `Try it out`.\n",
    "> - Click `Execute`. A new session will be created. Copy the session ID from the `Response body`.\n",
    "\n",
    "<a id=\"stop-session\"></a>\n",
    "5. Stop replay session\n",
    "\n",
    "> - Click `PUT /mktdata/session/stop/{sessionId}`.\n",
    "> - Click `Try it out`.\n",
    "> - Click `Execute`. Logs will confirm session has been stopped. `PUT` operations in REST are idempotent and produce the same result no matter how many times they are called. Interleaving different operations may produce different results.\n",
    "\n",
    "<a id=\"start-session\"></a>\n",
    "6. Start replay session\n",
    "\n",
    ">- Click `PUT /mktdata/session/start/{sessionId}`.\n",
    "> - Click `Try it out`.\n",
    "> - Paste session ID into `Session Id` textbox.\n",
    "> - Click `Execute`. This will start the newly created replay session. Replay service `TRACE` logs for published events will be visible in the terminal window. And after replay session completes, a summary will be logged\n",
    "      with the start time, end time, and duration of the replay session. This baseline replays the full dataset at **normal** speed in approximately `00:01:58 (1 minute, 58 seconds)`. Last market data event has `id=3453`.\n",
    "\n",
    "> - Once a session has completed playing the **full** market data stream, it is automatically **terminated**. Terminated sessions **cannot be restarted**. However, while a session is midstream, it may freely be started, stopped, rewound, forwarded, sped up or down, jumped to specific event.\n",
    "\n",
    "> [Create](#create-session) a brand new session and [start](#start-session) it. Before it finishes [stop](#stop-session).\n",
    "\n",
    "  <a id=\"rewind-session\"></a>\n",
    "7. Rewind session\n",
    "\n",
    "> - Click `PUT /mktdata/session/rewind/{sessionId}`, click `Try it out`, paste session ID into `Session Id` textbox, and click `Execute`. Logs will show the session has been rewound.\n",
    "\n",
    "<a id=\"change-replay-speed\"></a>\n",
    "8. Change replay speed\n",
    "\n",
    "> - Click `PUT /mktdata/session/speed/{sessionId}/{speed}`, click `Try it out`, paste session ID into `Session Id` textbox, enter 2.0 in `speed` textbox. Click `Execute`. Confirm replay speed has been doubled (see logs).\n",
    "\n",
    "9. [Start](#start-session) the replay session. Events will start streaming at the new speed. When this replay session finishes take a look at the service log tail. Replay **duration** should be approximately *half* the previous replay session since the stream was replayed at *twice* the normal speed.\n",
    "\n",
    "10. One final test to get a sense of the raw performance of replay server. First, [create](#create-session) a new replay session. Then [set](#change-replay-speed) replay speed for the new session to a large value, e.g. `1000.0`. Finally, [start](#start-session) the session. When this replay session finishes take a look the service log tail. Replay duration will be a much smaller number!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emfo",
   "metadata": {},
   "source": [
    "### Automation recipe for kicking the tires\n",
    "\n",
    "Manual testing works fine but it is cumbersome for runing lots of experiments. Manully testing streaming to hundreds of concurrent clients is not easy to accomplish.\n",
    "\n",
    "A great way to accomplish this is through a Notebook. [Performance](#performance) tests (see below) were conducted using this [Marimo](https://marimo.io) Notebook.\n",
    "\n",
    "#### Disable logging\n",
    "\n",
    "> For performance testing it is important that excessive logging is disabled. If you had earlier changed the logging level to `TRACE` for manual testing, now is a good time to revert back. Go to *application.properties*, locate `logging.level.com.pragma.demo=TRACE` and replace it with `logging.level.com.pragma.demo=INFO`.\n",
    "#### Prerequisites\n",
    "\n",
    "  - Python 3.9.\n",
    "  - Marimo.\n",
    "\n",
    "#### Marimo setup\n",
    "\n",
    "After successfully installing Marimo, open a command line terminal, execute `marimo tutorial intro`. This will launch Marimo with a introductory tutorial.\n",
    "\n",
    "Click on **settings icon** ⚙️ at the top right on Marimo page and from dropdown menu click `User settings`. Click `Runtime` and uncheck `Autorun on startup`. **This setting change is important** to prevent Marimo from auto-executing tests when the Notebook is loaded. We want control over running the tests!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hstk",
   "metadata": {},
   "source": [
    "#### Test setup\n",
    "\n",
    " - Either load the Notebook in Marimo, or exit Marimo, navigate to where this Notebook is stored, and run `marimo edit req_design_test.py`. This will start Marimo and open the Notebook for editing (without auto execution).\n",
    "\n",
    " - [Run](#running) the application in VSCode so that REST endpoints are ready for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies. \n",
    "# Async IO packages are needed to test concurrent sessions without blocking.\n",
    "import requests\n",
    "import time\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iLit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base URL for API\n",
    "BASE_URL = \"http://localhost:8080/mktdata/session\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for interacting with RESTful aPI\n",
    "from IPython.display import clear_output, display\n",
    "\n",
    "def decodeResponse(response : any) -> str:\n",
    "    \"\"\"\n",
    "    Decode response from REST endpoint. All PUT endpoints (create session, start, stop, rewind, jump) return string, GET endpoint (subscribe) returns a stream of JSON docs. This function handles both gracefully.\n",
    "    Args:\n",
    "        response - Response from replay service.\n",
    "    Returns:\n",
    "        str: The string or JSON response from replay service.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Try to parse JSON, if it fails, handle the string response\n",
    "        resp = response.json()\n",
    "    except ValueError:  # If JSON decoding fails\n",
    "        # Handle the case where response is a simple string\n",
    "        resp = response.text\n",
    "    return resp\n",
    "\n",
    "def compute_duration(start_datetime : datetime) -> str:\n",
    "    \"\"\"\n",
    "        Compute duration between a start time and now.\n",
    "\n",
    "        Args:\n",
    "            start_datetime (datetime): Start time.\n",
    "\n",
    "        Returns:\n",
    "\n",
    "            str: Duration formatted as hh:mm:ss.zzz\n",
    "    \"\"\"\n",
    "    duration = datetime.now() - start_datetime\n",
    "\n",
    "    total_seconds = duration.total_seconds()\n",
    "    hours, remainder = divmod(total_seconds, 3600)\n",
    "    minutes, remainder = divmod(remainder, 60)\n",
    "    seconds, milliseconds = divmod(remainder, 1)\n",
    "\n",
    "    return f\"{int(hours):02}:{int(minutes):02}:{int(seconds):02}:{int(milliseconds * 1000):03}\"\n",
    "\n",
    "def getSessionId(response : any) -> str:\n",
    "    return decodeResponse(response)\n",
    "\n",
    "def createSession() -> str:\n",
    "    \"\"\"\n",
    "    Create replay session.\n",
    "\n",
    "    Returns:\n",
    "        Session Id or None.\n",
    "    \"\"\"\n",
    "    create_url = BASE_URL\n",
    "    response = requests.post(create_url)\n",
    "    clear_output(wait=True)  # Clear previous output in Notebook\n",
    "    if response.status_code == 200:\n",
    "        session_id = getSessionId(response)\n",
    "        display(f\"Session created: {session_id}\", clear=True)\n",
    "    else:\n",
    "        display(f\"Failed to create session: {response.text}\")\n",
    "        session_id = None\n",
    "    return session_id\n",
    "\n",
    "def setSpeed(session_id : str, speed : float) -> None:\n",
    "    \"\"\"\n",
    "    Set replay speed.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Session Id.\n",
    "        speed: Replay speed. Must be POSITIVE.\n",
    "    \"\"\"\n",
    "    if session_id:\n",
    "        speed_url = f\"{BASE_URL}/speed/{session_id}/{speed}\"\n",
    "        response = requests.put(speed_url)\n",
    "        display(f\"{response.text}\", clear=True)\n",
    "\n",
    "def startSession(session_id : str) -> None:\n",
    "    \"\"\"\n",
    "    Start replay session. Event stream for this session will start publishing.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Session Id.\n",
    "    \"\"\"\n",
    "    if session_id:\n",
    "        start_url = f\"{BASE_URL}/start/{session_id}\"\n",
    "        response = requests.put(start_url)\n",
    "        display(f\"{response.text}\", clear=True)\n",
    "\n",
    "def stopSession(session_id : str) -> None:\n",
    "    \"\"\"\n",
    "    Stop replay session. Event stream for this session will stop publishing.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Session Id.\n",
    "    \"\"\"\n",
    "    if session_id:\n",
    "        stop_url = f\"{BASE_URL}/stop/{session_id}\"\n",
    "        response = requests.put(stop_url)\n",
    "        display(f\"{response.text}\", clear=True)\n",
    "\n",
    "def rewindSession(session_id : str) -> None:\n",
    "    \"\"\"\n",
    "    Rewind (reset) replay session to begging of event stream.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Session Id.\n",
    "    \"\"\"\n",
    "    if session_id:\n",
    "        rewind_url = f\"{BASE_URL}/rewind/{session_id}\"\n",
    "        response = requests.put(rewind_url)\n",
    "        display(f\"{response.text}\", clear=True)\n",
    "\n",
    "def forward(session_id : str, skip_count: int) -> None:\n",
    "    \"\"\"\n",
    "    Fast forward replay session by skipping one or more events.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Session Id.\n",
    "        skip_count (int): Number of events to skip. Must be POSITIVE. Forwarding past the end of event stream stops the session.\n",
    "    \"\"\"\n",
    "    if session_id:\n",
    "        forward_url = f\"{BASE_URL}/jump/{session_id}/{event_id}\"\n",
    "        response = requests.put(forward_url)\n",
    "        display(f\"{response.text}\", clear=True)\n",
    "\n",
    "def jumpToEvent(session_id : str, event_id: int) -> None:\n",
    "    \"\"\"\n",
    "    Jump to event in replay session.\n",
    "\n",
    "    Args:\n",
    "        session_id (str): Session Id.\n",
    "        event_id (int): Event Id.\n",
    "    \"\"\"\n",
    "    if session_id:\n",
    "        jump_url = f\"{BASE_URL}/jump/{session_id}/{event_id}\"\n",
    "        response = requests.put(jump_url)\n",
    "        print(f\"{response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ROlb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "\n",
    "async def subscribeSession(session_id : str) -> None:\n",
    "    \"\"\"\n",
    "    Subscribe to replay session. Starts listening for session event stream and precesses  event until the strem is closed by server.\n",
    "\n",
    "    Args:\n",
    "\n",
    "        session_id (str): Session Id.\n",
    "    \"\"\"\n",
    "    # if session_id:\n",
    "    #     start_datetime = datetime.now()\n",
    "\n",
    "    #     subscribe_url = f\"{BASE_URL}/subscribe/{session_id}\"\n",
    "    #     response = requests.get(subscribe_url, stream=True)\n",
    "\n",
    "    #     # Process and display streaming data\n",
    "    #     for chunk in response.iter_lines(decode_unicode=True):\n",
    "    #         try:\n",
    "    #             if chunk:\n",
    "    #                 pass\n",
    "    #         except KeyboardInterrupt:\n",
    "    #             display(f\"Subscribe session {session_id} stopped manually\", clear)\n",
    "\n",
    "    #     duration = compute_duration(start_datetime)\n",
    "    #     display(f\"Subscribe session {session_id} finished at {datetime.now()}: {duration}\", clear=True)\n",
    "    if session_id:\n",
    "\n",
    "        start_datetime = datetime.now()\n",
    "        subscribe_url = f\"{BASE_URL}/subscribe/{session_id}\"\n",
    "\n",
    "        async with aiohttp.ClientSession() as aiohttp_session:\n",
    "            try:\n",
    "                async with aiohttp_session.get(subscribe_url) as response:\n",
    "                    async for line in response.content.iter_any():\n",
    "                        chunk = line.decode('utf-8').strip()\n",
    "                        if chunk:\n",
    "                            try:\n",
    "                                pass  # Process the chunk here\n",
    "                            except KeyboardInterrupt:\n",
    "                                print(f\"Subscribe session {session_id} stopped manually\")\n",
    "            except aiohttp.ClientPayloadError:\n",
    "                display(\"Error: Response payload is incomplete.\")\n",
    "            except Exception as e:\n",
    "                display(f\"Unexpected error: {e}\")\n",
    "\n",
    "        duration = compute_duration(start_datetime)\n",
    "        display(f\"Subscribe session {session_id} finished at {datetime.now()}: {duration}\", clear=True)\n",
    "\n",
    "\n",
    "async def subscribeSessions(sessions : List[str]) -> None:\n",
    "    \"\"\"\n",
    "    Subscribe to 1 or more sessions.\n",
    "\n",
    "    Args:\n",
    "\n",
    "        sessions(List[str]) : Session Ids.\n",
    "    \"\"\"\n",
    "    tasks = [subscribeSession(session) for session in sessions]\n",
    "    await asyncio.gather(*tasks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qnkX",
   "metadata": {},
   "source": [
    "#### Set session count and replay speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TqIu",
   "metadata": {},
   "outputs": [],
   "source": [
    "SESSION_COUNT = 1\n",
    "SPEED = 1000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vxnm",
   "metadata": {},
   "source": [
    "#### Create sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "DnEU",
   "metadata": {},
   "outputs": [],
   "source": [
    "sessions = []\n",
    "\n",
    "for sesssion_count in range(0, SESSION_COUNT):\n",
    "    sessionId = createSession()\n",
    "    sessions.append(sessionId)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ulZA",
   "metadata": {},
   "source": [
    "#### Set session replay speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfG",
   "metadata": {},
   "outputs": [],
   "source": [
    "for speed_session in sessions:\n",
    "    setSpeed(speed_session, SPEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Pvdt",
   "metadata": {},
   "source": [
    "#### Start replay sessions and subscribe to event streams.\n",
    "\n",
    "This could be a long-running operation, a timer on right side of cell shows progress. Below the cell will be output of completion logs from sessions. Note, logs from last completing session will overwite previous output. Since REST calls are made asynchronously, it is possible that logs from long running sessions are overwritten by logs from shorter sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZBYS",
   "metadata": {},
   "outputs": [],
   "source": [
    "for start_session in sessions:\n",
    "    startSession(start_session)\n",
    "\n",
    "await subscribeSessions(sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aLJB",
   "metadata": {},
   "source": [
    "## Performance\n",
    "\n",
    "Below are performance test results were run on a Apple Macbook with 1.4 GHz Quad-Core Intel Core i5 with 16GB 2133 MHz RAM. Amazon Corretto 17 JDK, Heap Size (-Xmx and -Xms): 4096 MB. Client and server processes were running on same machine.\n",
    "\n",
    "Since testing was done using `localhost` (bypassing the physical network) there was no network latency, packet loss, or bandwidth constraints. However, clients are running inside a Marimo notebook with browser updates, which will have significant impact on performance with large number of concurrent clients.\n",
    "\n",
    "Baseline testcase is a single client running at replay `speed = 1.0` - it takes roughly `2 minutes` to publish all data events. With `[1, 10,100, 1000]` clients running at `speed = 1.0`, there is no performance impact.\n",
    "\n",
    "A single client running at replay `speed = 1000.0` received all events in `00:00:00:544`, which works out to roughly 6000 events/sec.\n",
    "\n",
    "| # Sessions | Replay Speed | Duration <br> `hh:mm:ss:zzz`|\n",
    "|------------|--------------|--------------|\n",
    "| 1          | 1            | 00:01:58:195 |\n",
    "| 10         | 1            | 00:01:58:172 |\n",
    "| 100        | 1            | 00:01:58:162 |\n",
    "| 1000       | 1            | 00:01:58:162 |\n",
    "|------------|--------------|--------------|\n",
    "| 1          | 10           | 00:00:11:818 |\n",
    "| 10         | 10           | 00:00:11:777 |\n",
    "| 100        | 10           | 00:00:11:787 |\n",
    "| 200        | 10           | 00:00:14:203 |\n",
    "| 400        | 10           | 00:00:22:156 |\n",
    "| 500        | 10           | 00:00:25:950 |\n",
    "| 600        | 10           | 00:00:32:068 |\n",
    "\n",
    "![performance latency plot](https://github.com/himalayahall/demo/blob/01cb141736dc521652c7aa6685c080ac31d9e7e7/src/main/marimo/performance.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nHfw",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sample list of timestamps with format hh:mm:ss (time taken for requests)\n",
    "times_in_seconds = [11, 11, 11, 14, 22, 25, 32]\n",
    "\n",
    "# Generate the X-axis labels representing the number of clients (1, 2, 3, ...)\n",
    "clients = [1, 10, 100, 200, 400, 500, 600]\n",
    "\n",
    "# Plot the processing times per client\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(clients, times_in_seconds, marker=\"o\", linestyle=\"-\", color=\"b\", label=\"Replay Time\")\n",
    "\n",
    "# Format the plot\n",
    "plt.xlabel(\"Number of Clients\")\n",
    "plt.ylabel(\"Replay Time (seconds)\")\n",
    "plt.title(\"Replay Time at Fixed Speed (10.0)\")\n",
    "plt.xticks(clients)  # Label X-axis with client numbers\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "xXTn",
   "metadata": {},
   "source": [
    "### Suggestions for Improving Performance\n",
    "\n",
    "- Run replay server and client on separate machines.\n",
    "- Make sure network interfaces on test machines support high throughput.\n",
    "- Carefully tune JVM and dependent libraries.\n",
    "- Use binary wire encoding like Google Proto to reduce network traffic.\n",
    "- Cache large datasets in a distributed cache like Redis.\n",
    "- Horizontal scaling -> launch additional replay server processes with a Load Balancer to fan out traffic among the servers. Sticky connections would pin client traffic to the same server.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "As above tests demonstrate, replay server satisfies all the [Functional](#functional) and [Non-Functional](#non-functional) requirements."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
